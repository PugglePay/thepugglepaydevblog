<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: torquebox | PugglePay]]></title>
  <link href="http://devblog.pugglepay.com/blog/categories/torquebox/atom.xml" rel="self"/>
  <link href="http://devblog.pugglepay.com/"/>
  <updated>2015-04-16T15:29:56+02:00</updated>
  <id>http://devblog.pugglepay.com/</id>
  <author>
    <name><![CDATA[dev]]></name>
    <email><![CDATA[dev@pugglepay.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Where is my stack? (Part 1): Goodbye Torquebox]]></title>
    <link href="http://devblog.pugglepay.com/blog/2013/10/09/where-is-my-stack-part-1-torquebox/"/>
    <updated>2013-10-09T13:30:00+02:00</updated>
    <id>http://devblog.pugglepay.com/blog/2013/10/09/where-is-my-stack-part-1-torquebox</id>
    <content type="html"><![CDATA[<p>So this is how it ends.</p>

<p>This week was the last week we ran TorqueBox in production. We've had
it running in production for 5 months. That's something! We
switched to TorqueBox in the first place to avoid headache with system
administration. Sadly, There Ain't No Such Thing As A Free Lunch
(TANSTAAFL), and we traded our problems with new ones, namely JRuby
and the JVM.</p>

<!-- more -->


<h2>Previously on "PugglePay"</h2>

<p>In an <a href="/blog/2013/05/03/torquebox-or-how-i-learned-to-stop-worrying-and-love-the-jvm/">earlier post</a>, I discussed some problem we had with TorqueBox from the very
beginning, but that we thought could overcome:</p>

<ul>
<li>slower tests</li>
<li>memory leaks</li>
<li>no zero-downtime deploy</li>
</ul>


<p>The only problem that was solved (and only recently) was the zero
downtime deploy. Other problems have appeared in the meantime:</p>

<ul>
<li>gem incompatibility</li>
<li>shaky OpenSSL support</li>
<li>very tricky setup with Spork</li>
<li>assets pre-compile that take forever</li>
</ul>


<h2>What to do?</h2>

<p>Most of those problems are related to JRuby, and I'm confident that
they will be solved someday. Another thing to point out is that we
migrated a fairly large application, so it might be easier to spot
memory leaks when building an app from the ground up.</p>

<p>But for our case, we reached the conclusion that TorqueBox was not a
good fit given our current needs, and went therefore the other way.</p>

<p>And that meant the Unix way.</p>

<p>Instead of adding the one big component, we've had to add a bunch of
smaller ones. We are now using Nginx+Passenger Enterprise as web-server,
Redis+Resque+resque_scheduler for cluster-wise scheduling, and Monit for
keeping all those services running.</p>

<p>So we did not want to become full-blown sysadmin, but that became the
only viable option for us.</p>

<p>We were only treating the symptom though, and not the decease: we did
not want to become Sysadmins because the tooling we've been using for
system administration were so painful to use.</p>

<p>So that's how it all began: with looking for a replacement for our
own mixture of ruby scripts and Chef recipes...</p>

<h2>On the next episode of PugglePay Development</h2>

<p>The team learns new encryption techniques ("We should totally use
GPG!"), discover new tools ("Ansible all the things!") and write some
libraries ("Mr. F~~").</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Torquebox or: How I Learned to Stop Worrying and Love the JVM]]></title>
    <link href="http://devblog.pugglepay.com/blog/2013/05/03/torquebox-or-how-i-learned-to-stop-worrying-and-love-the-jvm/"/>
    <updated>2013-05-03T10:42:00+02:00</updated>
    <id>http://devblog.pugglepay.com/blog/2013/05/03/torquebox-or-how-i-learned-to-stop-worrying-and-love-the-jvm</id>
    <content type="html"><![CDATA[<p>So here is the thing. As a DevOp, SysAdmin is a PITA. Time spent
tweaking the servers to add such or such service is time not spent
actually producing value.</p>

<p>At PugglePay, we try to be agile and always look at the trade-offs
that are involved in every decision we make. So as we started
developing our product, we decided to go with the easy and fast track,
and that meant Amazon, Rails and MySQL.</p>

<p>Unfortunately, easy does not necessary mean simple, so we kept using
the same tools to the point where easy became complex. It was time
for us to do something difficult which was to use more tools and turn our
architecture simple again.</p>

<!-- more -->


<p>The difficult thing for us was to move out of our comfort zone because
our comfort zone was a dangerous place (remember the frog being slowly
boiled to death).</p>

<h2>Our problem:</h2>

<ul>
<li><p>We needed queues. We kept on postponing using them because we wanted
to Keep It Simpleâ„¢, but simple meant using queues.</p></li>
<li><p>We needed daemons. Stuff that run non stop, and that get updated
after each deploy.</p></li>
<li><p>We needed scheduled jobs. We used cron for that, but that meant
the application and the server were tightly coupled. Not simple!
(but easy)</p></li>
</ul>


<p>If we look at all of the above, the easy solution would have been to
add a message processing lib like sidekiq, a short capistrano script
to redeploy our services and keep on using cron for recurring tasks.
But here comes the trick:</p>

<ul>
<li>We are going to need clustering. And we want all of the above to be
clustered.</li>
</ul>


<p>So as any good developer, we googled "rails queues cron clustering"
and found <a href="http://torquebox.org/">TorqueBox</a>.</p>

<h2>TorqueBox</h2>

<p>The idea of TorqueBox is to add a layer of abstraction between the
server and your application. It's like you are building a city, and
TorqueBox offers to provide the sewer system, running water,
electricity and the Internet so that you can focus on the city
planning.</p>

<p>In practice, that meant webserver, messaging, recurring jobs, and
daemons out of the box, and the only SysAdmin we have to take care of
is to get TorqueBox running.</p>

<p>Wow. That looked exactly like what we needed. Only downside: it runs on
JRuby. Which means JVM. And we had zero knowledge.</p>

<p>But the concept was just too good to be so easily dismissed because of our
own lack of knowledge. It would be difficult for us, but it could
become easy on the long run.</p>

<h2>Investigation</h2>

<p>So we started our investigation. The first step was to migrate our app
to JRuby. First downside: we got really slow tests. So that's the
first thing we had to improve.</p>

<p>The solution was to use <a href="https://github.com/sporkrb/spork">Spork</a> and
NailGun. What we got are fast enough tests. It's slower than with MRI
(10% slower on average), but good enough.</p>

<p>So running on JRuby: check! Next step was to get the app running
locally on TorqueBox. Roughly, that meant:</p>

<p><code>sh
gem install torquebox
torquebox run
torquebox deploy
</code></p>

<p>Boom. Trivial. Now let's deploy to Amazon. Well, there's a
<a href="https://github.com/torquebox/chef-cookbooks">chef recipe</a>. It
requires some extra work to get clustering going because Amazon does
not support multicasting (for automatic discovery of new nodes). Well,
clustering is for later, and for sure we're going to solve that
problem. So getting TorqueBox to run on Amazon: check!</p>

<p>Now let's deploy. Cool, there's a
<a href="https://rubygems.org/gems/torquebox-capistrano-support">Capistrano recipe</a>!
We already used capistrano, so that was easy. Boom! Deploying to
TorqueBox: check!</p>

<p>Sweet! Now lets deploy again! Yay, it works! And again! Yay! And
again! Oups... Nothing works anymore. Well, we knew exactly nothing
about JRuby, the JVM or TorqueBox, so it took us a week to find out
that after a redeploy the connections to the database were only closed
after Garbage Collection, but garbage collection came too late in our
case.</p>

<p>So the solution was to add an <code>at_exit</code> hook that took care of closing
all connections after redeploy.</p>

<p>We also realized that we do not get zero-downtime deploy when
deploying to TorqueBox. That's sad, because we are going to need it in
the future. After googling a little more, we found out that this is a
feature coming with the next release. Fair enough.</p>

<p>So after a couple of weeks of research and testing, we were confident
enough that TorqueBox would make our system much easier to maintain in
the future, and decided that the pros were bigger than the cons.</p>

<p>So we took a leap of faith and deployed the whole thing in production.</p>

<h2>Running in production</h2>

<p>It went pretty smoothly at first, but after a couple of deploy we got
a "PermGen out of memory" error. WTF is that?</p>

<p>Well, that's a story for another post. Long story short, closing the
DB connections was not enough because some references were being kept
that prevented the JRuby runtimes from being garbage collected after
each deploy. Also <code>jvisualvm</code> is an awesome tool that lets you inspect
a running JVM in realtime.</p>

<p>We have been running TorqueBox in production for a couple of weeks now,
and we are getting more familiar with it everyday. Our architecture is
much simpler, and the difficult bump we had to overcome is behind us.
So in the end, we believe that we have made the right choice.</p>

<p>But I think it is important to know that this was not a totally
painless migration. We had to learn about the JVM, how its garbage
collection works, which tool to use and which flags to set, while
making sure our development speed was not too much impacted by the
change. For us, it was worth it because we needed a better
infrastructure, and we did not want to rely on too many components.</p>

<h2>Conclusion</h2>

<p>Pros > Cons, lots of new things to learn, but the end
result is a simpler architecture.</p>

<p>We'd love to share more of what we know, but we'd love even more to
acquire knowledge from others. So if you have some experience with
TorqueBox, please get in touch!</p>
]]></content>
  </entry>
  
</feed>
